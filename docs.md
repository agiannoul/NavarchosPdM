# General
All timestamps are in the form of `pandas.Timestamp`.

## Datapoint (utils.structure)
Represents a data sample.

- **current**: an `ndarray`
- **reference**: a `DataFrame` of vectors that represent the reference set related to the data sample.
- **source**: a string indicating the source of the sample.
- **timestamp**: the timestamp of the sample.

## PredictionPoint - BatchPredictionPoint (utils.structure)
All predictions generated by `TechniquesHandlers` are in the form of `PredictionPoints`.

This is a simple class to represent a prediction, with the following fields:

- **score**: the anomaly score (list in case of Batch).
- **threshold**: threshold value (list in case of Batch).
- **alarm**: if this prediction causes an alarm (list in case of Batch).
- **thresholdtype**: metadata regarding the threshold technique used.
- **timestamp**: timestamp of prediction (list in case of Batch).
- **source**: The source that the prediction concerns.
- **description**: A description (a valid prediction should have the name of the technique).
- **notes**: Metadata (optional notes).
- **ensemble_details**: In case this prediction is from an ensemble technique, metadata text.

## EventPoint (utils.structure)
All events are in the form of `PredictionPoints`.

This is a simple class to represent a prediction, with the following fields:

- **code**: unique code of an event.
- **timestamp**: timestamp of the prediction.
- **source**: The source that the prediction concerns.
- **details**: Text, description, or any details.
- **type**: Metadata for the type of event (isolated, configuration, AD) used in context generation.

## Techniques Handlers (techniquesHandlers)
In their initialization, they should accept their parameters, source, and reset codes.
The source is a string that indicates the source of data that the Technique handler monitors. The reset codes are a list of tuples with all event codes and sources that may cause a reset in the technique (start over). The tuples in that list should be in the form of ev=(code, source) since they are tested like:
```python
if ev[0] == event.code and ev[1] == event.source: 
```

1. `get_Datapoint(timestamp, vector, source, description)`
   Feed an upcoming sample to the predictor, and a prediction is returned (when no available prediction, a `PredictionPoint` with None values should be returned).

   Returns a tuple: (PredictionPoint, Datapoint) - the prediction and the data in the form of Datapoint.

2. `get_event(Eventpoint)`
   Feed an upcoming event to the predictor.

   Returns a Boolean, PredictionPoint, Datapoint. A boolean value is returned if the event causes a reset in the technique. Moreover, some techniques (which perform batch prediction) return the predictions and the list of Datapoints that the prediction concerns (if these are None, they are ignored).


## Aggregators (utils.aggregators)

Classes that iplement different aggregators of resutlt:
this class should implement a method with name `transform`

1. `transform(listofPrection: list[PredictionPoint],lastpred: PredictionPoint) -> PredictionPoint:`
   The method accept a list of the previus predictions points, and the last prediction point.

    Returns a PredictionPoint after aggregating results (like averaging, or any aggregation user want to implement)

## Transformation (utils.transformation)

Classes that implement different transformation of raw data:
this class should implement a method with name `transform`

Is up to user implementation how will initialize the unbderlying model (e.g. in case of PCA or other)
when initializes the techniqeu.

1. `transform(row : numpy.ndarray) -> numpy.ndarray:`
    This method accept a raw data vector as numpy ndarray
     
    Returns a transformer numpy ndarra


## modeltemp (utils.structure)
A wrapper class representing a predictor (along with possible transformers or aggregators).

Parameters:

- **model**: A technique handler.
- **uid**: A unique id.
- **source**: The source of data that this model monitors.
- **name**: Name (the name should match with valid prediction points descriptions: see PredictionPoint).
- **needReference**: Boolean if the technique needs a reference data set to operate.
- **isbatch**: If the technique performs batch prediction (and returns BatchPredictionPoints).
- **transformations**: A transformation class in a list (e.g., `[FeatureGeneration]`), this is performed every time a Datapoint is collected.
- **aggregations**: An aggregation class in a list (e.g., `[Smoother]`), all predictions of the model are fed to the aggregator.

1. `get_data(pandas.Timestamp, raw data, source, description)`
   Collect a new sample, check if the source is the same as the source of the model.
   Apply the transformation on data (if any).
   Pass the data to the `get_data` of the model and collect the results.
   Pass the prediction to the aggregator (if any) and collect the result.
   Store the results of the aggregator and the model.

   Returns a tuple: (PredictionPoint, Datapoint) - the prediction and the data in the form of Datapoint.

2. `get_event(EventPoint)`
   Collect a new event.
   Feed the event to the model and collect the result (handles the return triplet of `Techniques Handlers get_event()`).
   In case the model produces a prediction based on this event, collect them and return them (if any).

   Returns a tuple: (PredictionPoint, Datapoint) - the prediction and the data in the form of Datapoint. None values in case of no prediction.


##  fuss (metafussion.fussionSystem)

The coordinator of models, data and event streams.

Parameters:

- **models**: A list of `utils.structure.modeltemp` objects

1. `collect_data( data, Timestamp, source, description):`
   Call the get_data() method of models with the same source as the new data sample
2. `collect_event( eventpoint: Eventpoint):`
   Call the get_event() method of all models
3. `debug_plot`
    Method used for visualization of the results. This method accept several lists (with event codes) which define two set of events, failure and events of interest to be plotted
4. `evaluation(self, failures=[], failurecodes=[], failuresources=[], plotThem=False, persource=False, PH="14 days",
                   lead="1 hours", beta=2)`
    This method evaluated the results using PdM evaluation framework.
    Need to specify: failure events and Predictive horizon. For more details look at evaluation framework